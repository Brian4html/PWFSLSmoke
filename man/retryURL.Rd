% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/retryURL.R
\name{retryURL}
\alias{retryURL}
\title{Download URL with Multiple Attempts}
\usage{
retryURL(url, curl = RCurl::getCurlHandle(), .opts = list(),
  .encoding = "UTF-8", tries = 6)
}
\arguments{
\item{url}{string with the URI}

\item{curl}{previously initialized CURL context/handle (see RCurl::getURL())}

\item{.opts}{named list of \code{CURLOptions} (see RCurl::getURL())}

\item{.encoding}{string identifying the encoding (see RCurl::getURL())}

\item{tries}{number of times to retry in the face of timeouts}
}
\value{
The text that is the HTTP response. (see RCurl::getURL())
}
\description{
This internal function provides a wrapper for RCurl::getURL() that mimics the
behavior of the unix \code{wget} command with the \code{--tries} flag. If a download fails
with an error message of \code{'Timeout was reached'} the function will sleep an increasing
amount of time before retrying the download up to \code{tries} times.

The amount of time to sleep stats at one second is increased by one second for each attempted download.
}
\references{
\url{http://www.omegahat.org/RCurl}
}
\keyword{internal}

